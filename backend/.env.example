# ===========================================
# Co-Op Backend Environment Configuration
# ===========================================
# Copy this file to .env and fill in your values
# All values should be in double quotes

# ===========================================
# Server Configuration
# ===========================================
NODE_ENV="development"
PORT="3000"
API_PREFIX="api/v1"

# ===========================================
# Database (PostgreSQL)
# Recommended: Supabase, Neon, or Render PostgreSQL
# ===========================================
DATABASE_URL="postgresql://postgres:[PASSWORD]@db.[PROJECT].supabase.co:5432/postgres"

# ===========================================
# Supabase (Auth & Storage)
# Get from: https://supabase.com/dashboard/project/[PROJECT]/settings/api
# ===========================================
SUPABASE_URL="https://[PROJECT].supabase.co"
SUPABASE_ANON_KEY="eyJ..."
SUPABASE_SERVICE_KEY="eyJ..."
SUPABASE_STORAGE_BUCKET="documents"

# ===========================================
# Upstash Redis - REST API (for caching)
# Get from: https://console.upstash.com
# Use the REST API URL and Token
# ===========================================
UPSTASH_REDIS_URL="https://[INSTANCE].upstash.io"
UPSTASH_REDIS_TOKEN="AX..."

# ===========================================
# Upstash Redis - Standard Connection (for BullMQ)
# Same instance, different format for BullMQ queues
# Get from: https://console.upstash.com (Details tab)
# ===========================================
UPSTASH_REDIS_HOST="[INSTANCE].upstash.io"
UPSTASH_REDIS_PORT="6379"
UPSTASH_REDIS_PASSWORD="AX..."

# ===========================================
# LLM Providers (configure at least ONE)
# All providers offer FREE tiers
# ===========================================

# Groq - Fast inference, generous free tier
# Get from: https://console.groq.com/keys
# Models: llama-3.3-70b-versatile, llama-4-scout, qwen-3-32b, kimi-k2
GROQ_API_KEY="gsk_..."

# Google AI Studio - Gemini models (RECOMMENDED)
# Get from: https://aistudio.google.com/app/apikey
# Models: gemini-1.5-flash (free tier)
# Also enables web research with Search Grounding
GOOGLE_AI_API_KEY="AI..."

# HuggingFace Inference API
# Get from: https://huggingface.co/settings/tokens
# Models: Mistral Small 24B, Phi-4, Gemma 2 27B, Llama 3.1 70B
HUGGINGFACE_API_KEY="hf_..."

# ===========================================
# LLM Council Configuration
# MANDATORY cross-critique between models
# Minimum 2 models required for council to function
# ===========================================
LLM_COUNCIL_MIN_MODELS="2"
LLM_COUNCIL_MAX_MODELS="5"

# ===========================================
# RAG Service (Optional)
# Separate Python service for document embeddings
# See /RAG folder for setup instructions
# ===========================================
RAG_SERVICE_URL="http://localhost:8000"
RAG_API_KEY="your-rag-api-key"

# ===========================================
# Web Research (Built-in)
# Primary: Google Gemini with Search Grounding
# Fallback: ScrapingBee (if Gemini fails)
# ===========================================
# Research is automatically enabled when GOOGLE_AI_API_KEY is set
# The research service uses Gemini with Google Search grounding
# for real-time web research (competitor analysis, investor search, etc.)

# ScrapingBee - Fallback web search (Optional)
# Get from: https://www.scrapingbee.com/
# Used when Gemini grounded search fails or is rate limited
SCRAPINGBEE_API_KEY=""

# ===========================================
# Notion Integration (Optional - Internal Integration)
# For exporting AI outputs to Notion pages
# 
# Setup:
# 1. Go to https://www.notion.so/my-integrations
# 2. Click "New integration"
# 3. Select your workspace, give it a name
# 4. Keep "Internal integration" selected (default)
# 5. Copy the "Internal Integration Secret" → NOTION_API_TOKEN
# 6. Go to Notion, open the page you want to export to
# 7. Click "..." → "Connections" → Add your integration
# 8. Copy the page ID from URL → NOTION_DEFAULT_PAGE_ID
#    (URL format: notion.so/Page-Name-{PAGE_ID})
# ===========================================
NOTION_API_TOKEN=""
NOTION_DEFAULT_PAGE_ID=""

# ===========================================
# Security
# ===========================================
# Master API key for internal service-to-service calls
# Generate with: openssl rand -hex 32
MASTER_API_KEY=""

# ===========================================
# Rate Limiting
# ===========================================
THROTTLE_TTL="60"
THROTTLE_LIMIT="100"

# ===========================================
# CORS Configuration
# Comma-separated list of allowed origins
# Use "*" for development only
# ===========================================
CORS_ORIGINS="http://localhost:3000,http://localhost:5173"

# ===========================================
# Logging
# Levels: error, warn, log, debug, verbose
# ===========================================
LOG_LEVEL="debug"
