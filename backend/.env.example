# ===========================================
# Co-Op Backend Environment Configuration
# ===========================================
# Copy this file to .env and fill in your values
# All values should be in double quotes

# ===========================================
# Server Configuration
# ===========================================
NODE_ENV="development"
PORT="3000"
API_PREFIX="api/v1"

# ===========================================
# Database (PostgreSQL)
# Recommended: Supabase, Neon, or Render PostgreSQL
# ===========================================
DATABASE_URL="postgresql://postgres:[PASSWORD]@db.[PROJECT].supabase.co:5432/postgres"

# ===========================================
# Supabase (Auth & Storage)
# Get from: https://supabase.com/dashboard/project/[PROJECT]/settings/api
# ===========================================
SUPABASE_URL="https://[PROJECT].supabase.co"
SUPABASE_ANON_KEY="eyJ..."
SUPABASE_SERVICE_KEY="eyJ..."
SUPABASE_STORAGE_BUCKET="documents"

# ===========================================
# Upstash Redis - REST API (for caching)
# Get from: https://console.upstash.com
# Use the REST API URL and Token
# ===========================================
UPSTASH_REDIS_URL="https://[INSTANCE].upstash.io"
UPSTASH_REDIS_TOKEN="AX..."

# ===========================================
# Upstash QStash - Serverless Message Queue
# Used for async agent job processing
# Get from: https://console.upstash.com/qstash
# ===========================================
QSTASH_TOKEN="eyJ..."
QSTASH_CURRENT_SIGNING_KEY="sig_..."
QSTASH_NEXT_SIGNING_KEY="sig_..."
# Callback URL for QStash webhooks (auto-detected on Render)
# QSTASH_CALLBACK_URL="https://your-app.onrender.com"

# ===========================================
# LLM Providers (configure at least ONE)
# All providers offer FREE tiers
# ===========================================

# Groq - Fast inference, generous free tier
# Get from: https://console.groq.com/keys
# Models: llama-3.3-70b-versatile, kimi-k2-instruct-0905
GROQ_API_KEY="gsk_..."

# Google AI Studio - Gemini models (RECOMMENDED)
# Get from: https://aistudio.google.com/app/apikey
# Models: gemini-2.5-flash
# Also enables web research with Search Grounding
GOOGLE_AI_API_KEY="AI..."

# HuggingFace Inference API
# Get from: https://huggingface.co/settings/tokens
# Models: deepseek-ai/DeepSeek-R1-Distill-Qwen-32B, microsoft/Phi-3-mini-4k-instruct, Qwen/Qwen2.5-14B-Instruct-1M
HUGGINGFACE_API_KEY="hf_..."

# ===========================================
# LLM Council Configuration
# MANDATORY cross-critique between models
# Minimum 2 models required for council to function
# Lower max = faster responses
# ===========================================
LLM_COUNCIL_MIN_MODELS="2"
LLM_COUNCIL_MAX_MODELS="3"

# ===========================================
# RAG Service (Required for Legal/Finance agents)
# Separate Python service for document embeddings
# See /RAG folder for setup instructions
# Domains: legal, finance
# Sectors: fintech, greentech, healthtech, saas, ecommerce
# ===========================================
RAG_SERVICE_URL="https://your-rag-service.koyeb.app"
RAG_API_KEY="your-rag-api-key"

# ===========================================
# Web Research (Built-in)
# Primary: Google Gemini with Search Grounding
# Fallback: ScrapingBee (if Gemini fails)
# ===========================================
# Research is automatically enabled when GOOGLE_AI_API_KEY is set
# The research service uses Gemini with Google Search grounding
# for real-time web research (competitor analysis, investor search, etc.)

# ScrapingBee - Fallback web search (Optional)
# Get from: https://www.scrapingbee.com/
# Used when Gemini grounded search fails or is rate limited
SCRAPINGBEE_API_KEY=""

# ===========================================
# Notion Integration (Optional - Internal Integration)
# For exporting AI outputs to Notion pages
# 
# Setup:
# 1. Go to https://www.notion.so/my-integrations
# 2. Click "New integration"
# 3. Select your workspace, give it a name
# 4. Keep "Internal integration" selected (default)
# 5. Copy the "Internal Integration Secret" → NOTION_API_TOKEN
# 6. Go to Notion, open the page you want to export to
# 7. Click "..." → "Connections" → Add your integration
# 8. Copy the page ID from URL → NOTION_DEFAULT_PAGE_ID
#    (URL format: notion.so/Page-Name-{PAGE_ID})
# ===========================================
NOTION_API_TOKEN=""
NOTION_DEFAULT_PAGE_ID=""

# ===========================================
# Security
# ===========================================
# Master API key for internal service-to-service calls
# Generate with: openssl rand -hex 32
MASTER_API_KEY=""

# Encryption key for sensitive data at rest (webhook secrets, etc.)
# Generate with: openssl rand -hex 32
# IMPORTANT: Keep this key safe - losing it means losing access to encrypted data
ENCRYPTION_KEY=""

# ===========================================
# Rate Limiting
# ===========================================
THROTTLE_TTL="60"
THROTTLE_LIMIT="100"

# ===========================================
# CORS Configuration
# Comma-separated list of allowed origins
# Use "*" for development only
# ===========================================
CORS_ORIGINS="http://localhost:3000,https://co-op-dev.vercel.app"

# ===========================================
# Logging
# Levels: error, warn, log, debug, verbose
# ===========================================
LOG_LEVEL="debug"
